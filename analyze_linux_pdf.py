"""
åˆ†æ Linuxæ•™ç¨‹.pdf çš„ç»“æ„
è¯†åˆ«ç« èŠ‚ã€ä»£ç å—ç­‰å…ƒç´ 
"""
from app.services.pdf import PDFParser, PDFExtractor
import sys
import os
import re
from pathlib import Path

os.chdir("backend")
sys.path.insert(0, ".")


def analyze_linux_tutorial():
    """åˆ†æ Linux æ•™ç¨‹çš„æ–‡æ¡£ç»“æ„"""
    print("=" * 70)
    print("ğŸ“š Linux æ•™ç¨‹ PDF ç»“æ„åˆ†æ")
    print("=" * 70)

    pdf_path = Path("../Linuxæ•™ç¨‹.pdf")

    if not pdf_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        return

    # 1. åŸºæœ¬ä¿¡æ¯
    print("\n1ï¸âƒ£ åŸºæœ¬ä¿¡æ¯:")
    parser = PDFParser(pdf_path)
    metadata = parser.get_metadata()
    print(f"   é¡µæ•°: {metadata['page_count']}")
    print(f"   ä½œè€…: {metadata.get('author', 'N/A')}")
    print(f"   æ ‡é¢˜: {metadata.get('title', 'N/A')}")

    # 2. æå–æ–‡æœ¬
    print("\n2ï¸âƒ£ æå–æ–‡æœ¬å†…å®¹...")
    extractor = PDFExtractor(pdf_path)
    structured_text = extractor.extract_structured_text()

    total_chars = sum(len(page['text']) for page in structured_text)
    print(f"   æ€»å­—ç¬¦æ•°: {total_chars:,}")
    print(f"   æœ‰æ•ˆé¡µæ•°: {len(structured_text)}")

    # 3. åˆ†æç« èŠ‚ç»“æ„
    print("\n3ï¸âƒ£ ç« èŠ‚ç»“æ„åˆ†æ:")
    chapter_pattern = re.compile(
        r'^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« |Chapter\s+\d+|[0-9]+\.?\s*[^\n]{1,50})\s*$',
        re.MULTILINE | re.IGNORECASE
    )
    section_pattern = re.compile(
        r'^([0-9]+\.[0-9]+\.?\s+[^\n]{1,80}|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€\.]\s*[^\n]{1,80})\s*$',
        re.MULTILINE
    )

    all_text = '\n\n'.join([page['text'] for page in structured_text[:10]])

    chapters = chapter_pattern.findall(all_text)
    sections = section_pattern.findall(all_text[:5000])

    print(f"   æ£€æµ‹åˆ°ç« èŠ‚æ ‡é¢˜: {len(chapters)} ä¸ª")
    if chapters:
        print(f"   å‰3ä¸ªç« èŠ‚:")
        for i, ch in enumerate(chapters[:3], 1):
            print(f"      {i}. {ch.strip()}")

    print(f"\n   æ£€æµ‹åˆ°å°èŠ‚æ ‡é¢˜: {len(sections)} ä¸ª")
    if sections:
        print(f"   å‰5ä¸ªå°èŠ‚:")
        for i, sec in enumerate(sections[:5], 1):
            print(f"      {i}. {sec.strip()}")

    # 4. åˆ†æä»£ç å—
    print("\n4ï¸âƒ£ ä»£ç å—åˆ†æ:")
    code_patterns = [
        r'```[\s\S]*?```',  # Markdown ä»£ç å—
        r'`[^`]+`',  # è¡Œå†…ä»£ç 
        r'^\s*[$#]\s+\w+',  # Shell å‘½ä»¤
        r'^\s{4,}\w+',  # ç¼©è¿›ä»£ç 
    ]

    sample_text = '\n'.join([page['text'] for page in structured_text[:5]])

    for i, pattern in enumerate(code_patterns, 1):
        matches = re.findall(pattern, sample_text, re.MULTILINE)
        print(f"   æ¨¡å¼ {i}: æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
        if matches and i <= 2:
            print(f"      ç¤ºä¾‹: {matches[0][:60]}...")

    # 5. æ˜¾ç¤ºå‰å‡ é¡µå†…å®¹ç¤ºä¾‹
    print("\n5ï¸âƒ£ å†…å®¹ç¤ºä¾‹ (ç¬¬1-2é¡µ):")
    for i, page in enumerate(structured_text[:2], 1):
        print(f"\n   --- ç¬¬ {i} é¡µ ---")
        text_preview = page['text'][:300]
        print(f"   {text_preview}...")
        print(f"   å­—ç¬¦æ•°: {len(page['text'])}")

    # 6. è¯†åˆ«æ–‡æ¡£ç±»å‹ç‰¹å¾
    print("\n6ï¸âƒ£ æ–‡æ¡£ç‰¹å¾è¯†åˆ«:")
    features = {
        'åŒ…å«ä»£ç ': bool(re.search(r'[$#]\s+\w+|```', all_text[:5000])),
        'åŒ…å«å‘½ä»¤': bool(re.search(r'(sudo|apt|yum|cd|ls|mkdir|chmod)', all_text[:5000], re.IGNORECASE)),
        'åŒ…å«ç« èŠ‚ç¼–å·': bool(re.search(r'^[0-9]+\.[0-9]+', all_text[:5000], re.MULTILINE)),
        'åŒ…å«ä¸­æ–‡': bool(re.search(r'[\u4e00-\u9fff]', all_text[:1000])),
        'åŒ…å«è‹±æ–‡': bool(re.search(r'[a-zA-Z]{3,}', all_text[:1000])),
    }

    for feature, exists in features.items():
        status = "âœ…" if exists else "âŒ"
        print(f"   {status} {feature}")

    print("\n" + "=" * 70)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    analyze_linux_tutorial()
