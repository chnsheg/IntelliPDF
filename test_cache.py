"""
æµ‹è¯• PDF è§£æç¼“å­˜åŠŸèƒ½
éªŒè¯ç¼“å­˜çš„ä¿å­˜å’ŒåŠ è½½
"""
from app.services.pdf import PDFExtractor, SectionChunker, get_pdf_cache
import sys
import os
import time
from pathlib import Path

# è®¾ç½®å·¥ä½œç›®å½•
os.chdir("backend")
sys.path.insert(0, ".")


def test_cache_functionality():
    """æµ‹è¯•ç¼“å­˜åŠŸèƒ½"""
    print("\n" + "="*70)
    print("ğŸ§ª PDF è§£æç¼“å­˜åŠŸèƒ½æµ‹è¯•")
    print("="*70)

    pdf_path = Path("../Linuxæ•™ç¨‹.pdf")

    if not pdf_path.exists():
        print(f"âŒ PDF æ–‡ä»¶ä¸å­˜åœ¨: {pdf_path}")
        return

    # è·å–ç¼“å­˜å®ä¾‹
    cache = get_pdf_cache()

    # æ¸…é™¤æ—§ç¼“å­˜
    print("\nğŸ“ æ¸…é™¤æ—§ç¼“å­˜...")
    cache.clear_cache(pdf_path)

    # ========== ç¬¬ä¸€æ¬¡è§£æï¼ˆæ— ç¼“å­˜ï¼‰ ==========
    print("\n" + "="*70)
    print("ğŸ”„ ç¬¬ä¸€æ¬¡è§£æï¼ˆæ— ç¼“å­˜ï¼‰")
    print("="*70)

    start_time = time.time()

    print("\n1ï¸âƒ£  æå–ç»“æ„åŒ–æ–‡æœ¬...")
    extractor = PDFExtractor(pdf_path, use_cache=True)
    structured_text = extractor.extract_structured_text()

    print(f"   âœ“ æå–äº† {len(structured_text)} é¡µ")

    print("\n2ï¸âƒ£  ç« èŠ‚åˆ†å—...")
    chunker = SectionChunker(use_cache=True)
    chunks = chunker.chunk_by_sections(structured_text, pdf_path)

    print(f"   âœ“ ç”Ÿæˆäº† {len(chunks)} ä¸ªç« èŠ‚å—")

    first_parse_time = time.time() - start_time
    print(f"\nâ±ï¸  ç¬¬ä¸€æ¬¡è§£æè€—æ—¶: {first_parse_time:.2f} ç§’")

    # ========== ç¬¬äºŒæ¬¡è§£æï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰ ==========
    print("\n" + "="*70)
    print("âš¡ ç¬¬äºŒæ¬¡è§£æï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰")
    print("="*70)

    start_time = time.time()

    print("\n1ï¸âƒ£  æå–ç»“æ„åŒ–æ–‡æœ¬...")
    extractor2 = PDFExtractor(pdf_path, use_cache=True)
    structured_text2 = extractor2.extract_structured_text()

    print(f"   âœ“ æå–äº† {len(structured_text2)} é¡µ")

    print("\n2ï¸âƒ£  ç« èŠ‚åˆ†å—...")
    chunker2 = SectionChunker(use_cache=True)
    chunks2 = chunker2.chunk_by_sections(structured_text2, pdf_path)

    print(f"   âœ“ ç”Ÿæˆäº† {len(chunks2)} ä¸ªç« èŠ‚å—")

    second_parse_time = time.time() - start_time
    print(f"\nâ±ï¸  ç¬¬äºŒæ¬¡è§£æè€—æ—¶: {second_parse_time:.2f} ç§’")

    # ========== æ€§èƒ½å¯¹æ¯” ==========
    print("\n" + "="*70)
    print("ğŸ“Š æ€§èƒ½å¯¹æ¯”")
    print("="*70)

    speedup = first_parse_time / second_parse_time if second_parse_time > 0 else 0
    time_saved = first_parse_time - second_parse_time

    print(f"\n   ç¬¬ä¸€æ¬¡è§£æ: {first_parse_time:.2f} ç§’")
    print(f"   ç¬¬äºŒæ¬¡è§£æ: {second_parse_time:.2f} ç§’")
    print(f"   âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(
        f"   ğŸ’° èŠ‚çœæ—¶é—´: {time_saved:.2f} ç§’ ({time_saved/first_parse_time*100:.1f}%)")

    # ========== ç¼“å­˜ç»Ÿè®¡ ==========
    print("\n" + "="*70)
    print("ğŸ“¦ ç¼“å­˜ç»Ÿè®¡")
    print("="*70)

    stats = cache.get_cache_stats()
    print(f"\n   ç¼“å­˜ç›®å½•: {stats['cache_dir']}")
    print(f"   å…ƒæ•°æ®ç¼“å­˜: {stats['metadata_count']} ä¸ª")
    print(f"   åˆ†å—ç¼“å­˜: {stats['chunks_count']} ä¸ª")
    print(f"   ç»“æ„åŒ–æ–‡æœ¬ç¼“å­˜: {stats['structured_text_count']} ä¸ª")
    print(f"   æ€»å¤§å°: {stats['total_size_mb']:.2f} MB")

    # ========== æ•°æ®ä¸€è‡´æ€§éªŒè¯ ==========
    print("\n" + "="*70)
    print("âœ… æ•°æ®ä¸€è‡´æ€§éªŒè¯")
    print("="*70)

    print(f"\n   ç»“æ„åŒ–æ–‡æœ¬é¡µæ•°: {len(structured_text)} == {len(structured_text2)}")
    print(f"   åˆ†å—æ•°é‡: {len(chunks)} == {len(chunks2)}")

    if len(chunks) > 0 and len(chunks2) > 0:
        print(
            f"   ç¬¬ä¸€ä¸ªå—å†…å®¹é•¿åº¦: {len(chunks[0]['text'])} == {len(chunks2[0]['text'])}")
        print(
            f"   æœ€åä¸€ä¸ªå—å†…å®¹é•¿åº¦: {len(chunks[-1]['text'])} == {len(chunks2[-1]['text'])}")

    # éªŒè¯æ•°æ®å®Œå…¨ä¸€è‡´
    assert len(structured_text) == len(structured_text2), "ç»“æ„åŒ–æ–‡æœ¬é¡µæ•°ä¸ä¸€è‡´"
    assert len(chunks) == len(chunks2), "åˆ†å—æ•°é‡ä¸ä¸€è‡´"

    print("\n   âœ… æ‰€æœ‰æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡ï¼")

    # ========== æ˜¾ç¤ºç¤ºä¾‹å— ==========
    print("\n" + "="*70)
    print("ğŸ“„ åˆ†å—ç¤ºä¾‹")
    print("="*70)

    if chunks:
        chunk = chunks[0]
        print(f"\n   ğŸ“ ç¬¬ä¸€ä¸ªå—:")
        print(f"   ç« èŠ‚: {chunk['chapter']}")
        print(f"   å°èŠ‚: {chunk['section']}")
        print(f"   é¡µç èŒƒå›´: {chunk['page_range']}")
        print(f"   å­—ç¬¦æ•°: {chunk['char_count']}")
        print(f"\n   å†…å®¹é¢„è§ˆ:")
        print(f"   {chunk['text'][:200]}...")

    print("\n" + "="*70)
    print("ğŸ‰ ç¼“å­˜åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
    print("="*70)


if __name__ == "__main__":
    test_cache_functionality()
